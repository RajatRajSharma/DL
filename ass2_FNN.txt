import random
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dense, Flatten
from tensorflow.keras.models import Sequential
from keras.datasets import mnist

(x_train, y_train), (x_test, y_test) = mnist.load_data()  # Load MNIST dataset
x_train = x_train / 255.0                                 # Normalize pixel values
x_test = x_test / 255.0
####################

model = Sequential()
model.add(Input(shape=(28, 28)))  # Input layer with shape 28x28
model.add(Flatten())               # Flatten to 1D vector
model.add(Dense(128, activation='relu'))
model.add(Dense(10, activation='softmax'))
####################

model.compile(optimizer="sgd",loss='sparse_categorical_crossentropy',metrics=["accuracy"])
####################

H=model.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=10)
####################

test_loss,test_acc=model.evaluate(x_test,y_test)
print("Loss=%.4f"%test_loss)
print("Accuracy=%4f"%test_acc)
####################

n=random.randint(0,9999)
plt.imshow(x_test[n])
plt.show()
####################

prediction=model.predict(x_test)
print("The handwritten number in the image is %d"%np.argmax(prediction[n]))
####################

plt.figure(figsize=(12, 4))

# Plot loss
plt.subplot(1, 2, 1)
plt.plot(H.history['loss'], label='train_loss')
plt.plot(H.history['val_loss'], label='val_loss')
plt.title('Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

# Plot accuracy
plt.subplot(1, 2, 2)
plt.plot(H.history['accuracy'], label='train_accuracy')
plt.plot(H.history['val_accuracy'], label='val_accuracy')
plt.title('Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

plt.show()